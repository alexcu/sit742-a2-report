\section{Method}
\label{sec:method}

\subsection{Assumptions}
\label{sec:method:assumptions}

\subsubsection{User Sessions}
\label{sec:method:assumptions:user_sessions}

A \textit{web session} is defined as a single session of a particular user at a given moment of time. It consists of what pages were visited within that period of time, as determined by the requests made to the server in this period.

To extrapolate meaningful data, the definition of \textit{what} a user session was needed to be determined. This is because we need to find patterns made in one particular user session; when a user visits the website in one sitting, what pages do they visit and in what order?

To do this, we assume that a session is made up of the following factors within a series of web requests:

\begin{enumerate}
  \item The client's IP address must be the same,
  \item The client's user agent string must be the same,
  \item The timestamp of the session is grouped in the same day, and
  \item The timestamp of the session is within the same hour.
\end{enumerate}

We group every request using these four key factors, using a hash as a delimiter, into the field \texttt{session\_identifier}. Using this identifier, we can group up a series of requests into one particular session. For example, a sample request is made to the server:

\begin{itemize}
  \item The \texttt{c\_ip} field is \texttt{1.2.3.4},
  \item The \texttt{user\_agent} field is \texttt{Safari},
  \item The \texttt{timestamp} field is \texttt{Tue Feb 29 03:18:00 GMT 2017}
\end{itemize}

Therefore the \texttt{session\_identifier} would be:

\begin{lstlisting}
      1.2.3.4#Safari#29-02-2017#03
\end{lstlisting}

Hence, multiple requests made within the 3rd hour of the 29th of February 2017 by the IP address \texttt{1.2.3.4} with the user agent \texttt{Safari} will be gathered together. Obviously this example is trivial and is more detailed in practice, but as an explanation it helps to be simple.

Advantages of this approach is that there can be multiple requests made from a single IP address that \textit{are not} from the same user agent. For example, internal requests made by users within the hotel would use different computers, and therefore different \texttt{user\_agent} strings would be made, making the session identifier unique.

Disadvantages of this approach are that there could be two users on an internal network (i.e., same \texttt{client\_ip}) using the \textit{exact} same user agent within the same exact hour who are technically not the same person. Additionally, by grouping sessions by the hour, any session that was near the hour may be split into two sessions. These are some limitations of our approach.

\subsubsection{Selection of Resources}
\label{sec:method:assumptions:selection_of_resources}

Not all requests were included in the analysis, as some requests were simply resource requests. We want to focus purely on \textit{informational resources}, and therefore need to filter the number of requests to those that are relevant.

To do this, we consider the following:

\begin{enumerate}
  \item The request resource is non-multimedia or functional, but informational. That is, requests whose resources are not JavaScript, Cascading Style Sheets, Images and the like, but rather ASPX and ASHX files (ASP.NET and Generic Web Handler pages that contain information about the hotel).
  \item The request resource is not under the directories \texttt{media}, \texttt{layouts}, or \texttt{sitecore}, as these directories do not contain informational resources.
  \item The request returns a client status that is only 200 (Success), or is not a placeholder page for a status page, e.g., a \texttt{404.aspx} page would not be appropriate to consider.
\end{enumerate}

Additionally, we make all request resources consistent for comparison by making them all lower case, which is made visible in the diagrams shown in Section~\ref{sec:results}.

\subsection{Extraction Process}
\label{sec:method:extraction_process}

\subsubsection{IP Address Source Regular Expression}
\label{sec:method:extraction_process:ip_regex}

To differentiate between private site visitors and external visitors, a regular expression was used to filter the private and public IP address ranges. The regular expression is shown below:

\begin{lstlisting}[language=SQL, xleftmargin=2cm]
WHERE l.c_ip REGEXP 
	'(^127\.)|(^10\.) | 
	 (^172\.1[6-9]\.) |
	 (^172\.2[0-9]\.) |
	 (^172\.3[0-1]\.) |
	 (^192\.168\.)'
\end{lstlisting}

Negating this \texttt{WHERE} clause of the regular expression will select only public IP addresses.

\subsubsection{Construction of SQL Queries}
\label{sec:method:extraction_process:sql_queries}

% TODO: Write how we construct our SQL queries

\subsection{Data Mining}

% TODO: Write how we mine the data (what framework etc.)